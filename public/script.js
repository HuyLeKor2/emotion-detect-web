// ====== Cáº¤U HÃŒNH ======
// Use CDN-hosted model weights per user request
const MODEL_URL = "https://cdn.jsdelivr.net/gh/cgarciagl/face-api.js/weights";

// Báº£n Ä‘á»“ label VN + message
const EMO_LABEL = {
    happy: "Vui váº» ðŸ˜„",
    sad: "Buá»“n bÃ£ ðŸ˜¢",
    angry: "Giáº­n dá»¯ ðŸ˜¡",
    fear: "Sá»£ hÃ£i ðŸ˜±",
    unknown: "Thá»­ láº¡i nhen ðŸ˜•"
};
const EMO_ICON = {
    happy: "icons/happy.gif",
    sad: "icons/sad.gif",
    angry: "icons/angry.gif",
    fear: "icons/fear.gif",
    unknown: "" // khÃ´ng icon
};
const EMO_MSG = {
    happy: [
        "Happy teachers, happy students!",
        "Ná»¥ cÆ°á»i cá»§a tháº§y cÃ´ lÃ  Ä‘á»™ng lá»±c lá»›n nháº¥t cho há»c sinh.",
        "NÄƒng lÆ°á»£ng tÃ­ch cá»±c cá»§a tháº§y cÃ´ lÃ  chÃ¬a khÃ³a má»Ÿ ra cÃ¡nh cá»­a tri thá»©c.",
        "Tháº§y cÃ´ háº¡nh phÃºc, lá»›p há»c sáº½ trÃ n Ä‘áº§y niá»m vui vÃ  sá»± sÃ¡ng táº¡o.",
        "HÃ£y lan tá»a niá»m vui nÃ y, vÃ¬ má»—i giá» há»c háº¡nh phÃºc lÃ  má»™t ká»· niá»‡m Ä‘áº¹p."
    ],
    sad: [
        "Má»—i cáº£m xÃºc Ä‘á»u cáº§n Ä‘Æ°á»£c láº¯ng nghe.",
        "KhÃ´ng sao Ä‘Ã¢u, nhá»¯ng khoáº£nh kháº¯c tráº§m láº¯ng giÃºp ta hiá»ƒu mÃ¬nh hÆ¡n.",
        "HÃ£y cho phÃ©p báº£n thÃ¢n nghá»‰ ngÆ¡i, rá»“i mÃ¬nh láº¡i bÆ°á»›c tiáº¿p."
    ],
    angry: [
        "Biáº¿n nÄƒng lÆ°á»£ng tiÃªu cá»±c thÃ nh hÃ nh Ä‘á»™ng tÃ­ch cá»±c.",
        "HÃ­t thá»Ÿ sÃ¢u, tÃ¢m trÃ­ bÃ¬nh tÄ©nh má»›i ra quyáº¿t Ä‘á»‹nh Ä‘Ãºng.",
        "DÃ¹ng sá»± tá»©c giáº­n lÃ m Ä‘á»™ng lá»±c Ä‘á»ƒ thay Ä‘á»•i."
    ],
    fear: [
        "Can Ä‘áº£m Ä‘á»‘i diá»‡n vÃ  vÆ°á»£t qua ná»—i sá»£.",
        "Ná»—i sá»£ lÃ  tÃ­n hiá»‡uâ€”chuyá»ƒn hÃ³a nÃ³ thÃ nh sá»± tá»± tin.",
        "Má»i thá»­ thÃ¡ch Ä‘á»u áº©n cÆ¡ há»™i."
    ],
    unknown: [
        "MÃ¬nh khÃ´ng cháº¯c láº¯m, thá»­ chá»¥p láº¡i nhÃ©!",
        "KhÃ´ng phÃ¡t hiá»‡n rÃµ cáº£m xÃºc. Báº¡n thá»­ láº§n ná»¯a nhÃ©."
    ]
};

// ====== DOM ======
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const btnCapture = document.getElementById("btnCapture");

const popup = document.getElementById("popup");
const snapshot = document.getElementById("snapshot");
const emoIcon = document.getElementById("emoIcon");
const emoLabel = document.getElementById("emoLabel");
const titleAsk = document.getElementById("titleAsk");
const letter = document.getElementById("letter");
const msgBox = document.getElementById("msgBox");
const btnClose = document.getElementById("btnClose");

// ====== STATE ======
let modelsReady = false;
let detecting = false;
let popupShown = false;
let videoReady = false;
let ssdAvailable = false;
let tinyAvailable = false;

// ====== UTIL ======
const pick = (arr) => arr[Math.floor(Math.random() * arr.length)];
const hideEl = (el) => el.classList.add("hidden");
const showEl = (el) => el.classList.remove("hidden");

function resetPopupUI() {
    // giá»‘ng PyQt: khi má»›i má»Ÿ popup, hiá»‡n title + thÆ° + pointer; áº©n message
    emoIcon.src = "";
    emoLabel.textContent = "â€¦";
    showEl(titleAsk);
    showEl(letter);
    hideEl(msgBox);
    // há»§y click cÅ© náº¿u cÃ³ Ä‘á»ƒ trÃ¡nh nhÃ¢n Ä‘Ã´i listener
    letter.onclick = null;
}

function showPopup() {
    popup.setAttribute("aria-hidden", "false");
    popup.style.display = "flex";
    popupShown = true;
}

function hidePopup() {
    popup.setAttribute("aria-hidden", "true");
    popup.style.display = "none";
    popupShown = false;
    resetPopupUI(); // chuáº©n bá»‹ cho láº§n sau
}

// ====== INIT (KHÃ”NG má»Ÿ popup á»Ÿ Ä‘Ã¢y) ======
async function init() {
    // Ä‘áº£m báº£o modal áº©n khi khá»Ÿi Ä‘á»™ng
    hideEl(popup);

    // camera
    try {
        // Prefer a built-in / computer webcam when multiple devices are present.
        async function getPreferredCameraStream() {
            // enumerate devices
            let devices = await navigator.mediaDevices.enumerateDevices();
            // if labels are empty (no permission yet), request a temporary stream to prompt user and then re-enumerate
            const labelsEmpty = devices.every(d => !d.label);
            if (labelsEmpty) {
                console.log('[camera] labels empty, requesting temporary permission to enumerate devices');
                let tmpStream = null;
                try {
                    tmpStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                    // stop tracks immediately after permission granted
                    tmpStream.getTracks().forEach(t => t.stop());
                } catch (e) {
                    console.warn('[camera] temporary permission denied or failed', e);
                }
                devices = await navigator.mediaDevices.enumerateDevices();
            }
            const videoDevices = devices.filter(d => d.kind === 'videoinput');
            console.log('[camera] available devices:', videoDevices.map(d => ({ id: d.deviceId, label: d.label })));

            if (videoDevices.length === 0) {
                // no device found
                return navigator.mediaDevices.getUserMedia({ video: true, audio: false });
            }

            // heuristics to prefer built-in/computer webcams
            const positive = ['integrated', 'internal', 'built-in', 'built in', 'webcam', 'face time', 'facetime', 'logitech', 'hd'];
            const negative = ['iphone', 'android', 'phone', 'pixel', 'galaxy'];

            // try to find device whose label matches positive and not negative
            let chosen = videoDevices.find(d => {
                const lbl = (d.label || '').toLowerCase();
                return positive.some(p => lbl.includes(p)) && !negative.some(n => lbl.includes(n));
            });

            if (!chosen) {
                // try a device that does not look like a phone
                chosen = videoDevices.find(d => {
                    const lbl = (d.label || '').toLowerCase();
                    return !negative.some(n => lbl.includes(n));
                });
            }

            if (chosen && chosen.deviceId) {
                console.log('[camera] chosen device:', chosen.label || chosen.deviceId);
                try {
                    return await navigator.mediaDevices.getUserMedia({ video: { deviceId: { exact: chosen.deviceId } }, audio: false });
                } catch (e) {
                    console.warn('[camera] failed to open chosen device, falling back', e);
                }
            }

            // fallback to facingMode user
            try {
                return await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
            } catch (e) {
                // last resort
                return await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
            }
        }

        const stream = await getPreferredCameraStream();
        video.srcObject = stream;
        // listen for playing to mark video ready
        video.addEventListener('playing', () => {
            console.log('[camera] video playing -> ready');
            videoReady = true;
            // enable capture only when models are ready too
            btnCapture.disabled = !(modelsReady && videoReady);
        }, { once: true });
    } catch (e) {
        alert("KhÃ´ng má»Ÿ Ä‘Æ°á»£c camera. HÃ£y kiá»ƒm tra quyá»n truy cáº­p.");
        console.error(e);
    }

    // models - check manifests first to avoid 404 for missing model builds
    try {
        async function manifestExists(name) {
            try {
                const url = `${MODEL_URL}/${name}_model-weights_manifest.json`;
                const r = await fetch(url, { method: 'GET' });
                return r.ok;
            } catch (e) {
                return false;
            }
        }

        const needFaceExpr = await manifestExists('face_expression');
        const hasTiny = await manifestExists('tiny_face_detector');
        const hasSsd = await manifestExists('ssd_mobilenetv1');

        if (!needFaceExpr) {
            throw new Error('Required model face_expression not found in ' + MODEL_URL);
        }

        // load face expression for sure
        await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);

        // load detectors that exist and set flags
        if (hasSsd) {
            await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
            ssdAvailable = true;
            console.log('[models] ssdMobilenetv1 loaded');
        }
        if (hasTiny) {
            await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
            tinyAvailable = true;
            console.log('[models] tinyFaceDetector loaded');
        }

        if (!ssdAvailable && !tinyAvailable) {
            throw new Error('No face detector model found (ssd_mobilenetv1 or tiny_face_detector) in ' + MODEL_URL);
        }

        modelsReady = true;
        console.log('[models] models loaded, ssd=', ssdAvailable, 'tiny=', tinyAvailable);
        btnCapture.disabled = !(modelsReady && videoReady);
    } catch (e) {
        console.error('Load models lá»—i:', e);
        btnCapture.disabled = true;
    }
}

// ====== EMOTION HELPERS ======
function mapTopEmotion(expressions) {
    const mapped = {
        happy: expressions.happy ?? 0,
        sad: expressions.sad ?? 0,
        angry: expressions.angry ?? 0,
        fear: expressions.fearful ?? (expressions.fear ?? 0)
    };
    let key = "unknown", score = 0;
    Object.entries(mapped).forEach(([k, v]) => { if (v > score) { score = v; key = k; } });
    return key;
}

// ====== CAPTURE FLOW (chá»‰ gá»i khi ngÆ°á»i dÃ¹ng báº¥m nÃºt / Space) ======
async function captureAndAnalyze() {
    if (!modelsReady || detecting) return;
    detecting = true;
    btnCapture.disabled = true;

    try {
        const w = video.videoWidth, h = video.videoHeight;
        if (!w || !h) throw new Error("Video chÆ°a sáºµn sÃ ng");

        // crop vuÃ´ng nhÆ° báº£n Python
        const minEdge = Math.min(w, h);
        const sx = (w - minEdge) / 2, sy = (h - minEdge) / 2;
        canvas.width = minEdge; canvas.height = minEdge;
        const ctx = canvas.getContext("2d");
        ctx.drawImage(video, sx, sy, minEdge, minEdge, 0, 0, minEdge, minEdge);
        const dataUrl = canvas.toDataURL("image/jpeg", 0.9);
        // Show the original captured square image in the popup.
        // Keep this as the snapshot displayed to the user.
        snapshot.src = dataUrl;

        // detect
        // use the canvas element directly as input for face-api (avoid bufferToImage Blob error)
        const input = canvas; // canvas already contains the cropped image
        console.log('[detect] running detection, ssdAvailable=', ssdAvailable, 'tinyAvailable=', tinyAvailable);
        // Robust detection routine: try SSD (if available), then multiple Tiny configs
        async function attemptDetect(img) {
            // try SSD first
            if (ssdAvailable) {
                console.log('[detect] trying SSD minConfidence=0.3');
                const d = await faceapi.detectAllFaces(img, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.3 })).withFaceExpressions();
                if (d && d.length) return { detections: d, method: 'ssd' };
            }

            if (tinyAvailable) {
                const tinyConfigs = [
                    { inputSize: 512, scoreThreshold: 0.25 },
                    { inputSize: 416, scoreThreshold: 0.2 },
                    { inputSize: 320, scoreThreshold: 0.15 },
                    { inputSize: 256, scoreThreshold: 0.12 }
                ];
                for (const cfg of tinyConfigs) {
                    try {
                        console.log('[detect] trying tiny', cfg);
                        const d = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions(cfg)).withFaceExpressions();
                        if (d && d.length) return { detections: d, method: `tiny-${cfg.inputSize}-${cfg.scoreThreshold}` };
                    } catch (e) {
                        console.warn('[detect] tiny attempt failed', cfg, e);
                    }
                }
                // last resort: detect single face with very low threshold
                try {
                    console.log('[detect] trying detectSingleFace tiny fallback');
                    const single = await faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions({ inputSize: 512, scoreThreshold: 0.08 })).withFaceExpressions();
                    if (single) return { detections: [single], method: 'tiny-single-fallback' };
                } catch (e) {
                    console.warn('[detect] single fallback failed', e);
                }
            }

            return { detections: [], method: 'none' };
        }

        const detectResult = await attemptDetect(input);
        const detections = detectResult.detections || [];
        console.log('[detect] method used:', detectResult.method);

        resetPopupUI(); // tráº¡ng thÃ¡i má»Ÿ Ä‘áº§u cá»§a popup

        console.log('[detect] detections length=', detections.length, detections);
        if (!detections.length) {
            // KhÃ´ng tháº¥y máº·t â†’ unknown nhÆ° Python
            emoIcon.src = EMO_ICON.unknown;
            emoLabel.textContent = EMO_LABEL.unknown;
            // phong bÃ¬ má»Ÿ â†’ hiá»‡n thÃ´ng Ä‘iá»‡p unknown khi click
            letter.onclick = () => {
                hideEl(titleAsk);
                hideEl(letter);
                msgBox.textContent = pick(EMO_MSG.unknown);
                showEl(msgBox);
            };
            showPopup();
            return;
        }

        // Chá»n máº·t lá»›n nháº¥t
        const biggest = detections.reduce((max, cur) =>
            cur.detection.box.area > max.detection.box.area ? cur : max
        );

        const key = mapTopEmotion(biggest.expressions);
        emoIcon.src = EMO_ICON[key] || "";
        emoLabel.textContent = EMO_LABEL[key] || EMO_LABEL.unknown;

        // Crop the face ROI from canvas for internal use (e.g., if you want to
        // save/send the face crop). Important: do NOT overwrite the visible
        // `snapshot.src` â€” keep showing the original captured image to the user.
        let faceCropDataUrl = null;
        try {
            const box = biggest.detection.box;
            const faceCanvas = document.createElement('canvas');
            faceCanvas.width = box.width; faceCanvas.height = box.height;
            const fctx = faceCanvas.getContext('2d');
            // source coordinates were drawn centered into canvas earlier using sx,sy
            // our canvas is the cropped square, so box.x and box.y are relative to canvas
            fctx.drawImage(canvas, box.x, box.y, box.width, box.height, 0, 0, box.width, box.height);
            faceCropDataUrl = faceCanvas.toDataURL('image/jpeg', 0.9);
            // If you later want to display the crop instead, set snapshot.src = faceCropDataUrl;
        } catch (e) {
            // fallback: keep original captured image visible; store the full canvas data if needed
            faceCropDataUrl = canvas.toDataURL('image/jpeg', 0.9);
        }

        // click phong bÃ¬ Ä‘á»ƒ lá»™ thÃ´ng Ä‘iá»‡p tÆ°Æ¡ng á»©ng
        letter.onclick = () => {
            hideEl(titleAsk);
            hideEl(letter);
            msgBox.textContent = pick(EMO_MSG[key] || EMO_MSG.unknown);
            showEl(msgBox);
        };

        showPopup();

    } catch (e) {
        console.error(e);
        // trong trÆ°á»ng há»£p lá»—i khi ngÆ°á»i dÃ¹ng Ä‘Ã£ báº¥m, ta váº«n má»Ÿ popup bÃ¡o thá»­ láº¡i
        resetPopupUI();
        emoIcon.src = "";
        emoLabel.textContent = "Thá»­ láº¡i ðŸ˜•";
        letter.onclick = () => {
            hideEl(titleAsk);
            hideEl(letter);
            msgBox.textContent = pick(EMO_MSG.unknown);
            showEl(msgBox);
        };
        showPopup();
    } finally {
        detecting = false;
        btnCapture.disabled = !modelsReady;
    }
}

// ====== EVENTS ======
// Soft restart helper: when user wants to 'restart' the app without reloading the page
async function restartApp() {
    try {
        // If a popup is visible, hide it (acts like pressing the close button)
        if (popupShown) {
            hidePopup();
            return;
        }

        // stop existing camera tracks if any
        if (video && video.srcObject) {
            try {
                const tracks = video.srcObject.getTracks();
                tracks.forEach(t => t.stop());
            } catch (e) {
                console.warn('[restart] stop tracks failed', e);
            }
            video.srcObject = null;
        }

        // reset some internal flags and UI
        detecting = false;
        videoReady = false;
        popupShown = false;
        resetPopupUI();
        btnCapture.disabled = true;

        // re-run initialization (re-acquire camera and re-check models)
        await init();
    } catch (e) {
        console.error('[restart] failed', e);
    }
}

// 'r' key: act like close popup or restart app (but not a full page reload)
window.addEventListener('keydown', (ev) => {
    // ignore when user is typing into an input or textarea or contenteditable
    const active = document.activeElement;
    const tag = active && active.tagName ? active.tagName.toLowerCase() : '';
    const isTyping = active && (active.isContentEditable || tag === 'input' || tag === 'textarea');
    if (isTyping) return;

    if (ev.key === 'r' || ev.key === 'R') {
        ev.preventDefault();
        // call restartApp (it may be async, don't block)
        restartApp();
    }
});



btnCapture.addEventListener("click", captureAndAnalyze);

// Space: giá»‘ng Python â€” Ä‘ang má»Ÿ popup thÃ¬ Ä‘Ã³ng, ngÆ°á»£c láº¡i thÃ¬ chá»¥p
window.addEventListener("keydown", (ev) => {
    if (ev.code === "Space") {
        ev.preventDefault();
        if (popupShown) hidePopup();
        else captureAndAnalyze();
    }
});

btnClose.addEventListener("click", hidePopup);
window.addEventListener("load", init);
