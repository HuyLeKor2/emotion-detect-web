// ====== C·∫§U H√åNH ======
// Use CDN-hosted model weights per user request
const MODEL_URL = "https://cdn.jsdelivr.net/gh/cgarciagl/face-api.js/weights";

// B·∫£n ƒë·ªì label VN + message
const EMO_LABEL = {
    happy: "Vui v·∫ª üòÑ",
    sad: "Bu·ªìn b√£ üò¢",
    angry: "Gi·∫≠n d·ªØ üò°",
    fear: "S·ª£ h√£i üò±",
    unknown: "Th·ª≠ l·∫°i nhen üòï"
};
const EMO_ICON = {
    happy: "icons/happy.gif",
    sad: "icons/sad.gif",
    angry: "icons/angry.gif",
    fear: "icons/fear.gif",
    unknown: "" // kh√¥ng icon
};
const EMO_MSG = {
    happy: [
        "Happy teachers, happy students!",
        "N·ª• c∆∞·ªùi c·ªßa th·∫ßy c√¥ l√† ƒë·ªông l·ª±c l·ªõn nh·∫•t cho h·ªçc sinh.",
        "NƒÉng l∆∞·ª£ng t√≠ch c·ª±c c·ªßa th·∫ßy c√¥ l√† ch√¨a kh√≥a m·ªü ra c√°nh c·ª≠a tri th·ª©c.",
        "Th·∫ßy c√¥ h·∫°nh ph√∫c, l·ªõp h·ªçc s·∫Ω tr√†n ƒë·∫ßy ni·ªÅm vui v√† s·ª± s√°ng t·∫°o.",
        "H√£y lan t·ªèa ni·ªÅm vui n√†y, v√¨ m·ªói gi·ªù h·ªçc h·∫°nh ph√∫c l√† m·ªôt k·ª∑ ni·ªám ƒë·∫πp."
    ],
    sad: [
        "M·ªói c·∫£m x√∫c ƒë·ªÅu c·∫ßn ƒë∆∞·ª£c l·∫Øng nghe.",
        "Kh√¥ng sao ƒë√¢u, nh·ªØng kho·∫£nh kh·∫Øc tr·∫ßm l·∫Øng gi√∫p ta hi·ªÉu m√¨nh h∆°n.",
        "H√£y cho ph√©p b·∫£n th√¢n ngh·ªâ ng∆°i, r·ªìi m√¨nh l·∫°i b∆∞·ªõc ti·∫øp."
    ],
    angry: [
        "Bi·∫øn nƒÉng l∆∞·ª£ng ti√™u c·ª±c th√†nh h√†nh ƒë·ªông t√≠ch c·ª±c.",
        "H√≠t th·ªü s√¢u, t√¢m tr√≠ b√¨nh tƒ©nh m·ªõi ra quy·∫øt ƒë·ªãnh ƒë√∫ng.",
        "D√πng s·ª± t·ª©c gi·∫≠n l√†m ƒë·ªông l·ª±c ƒë·ªÉ thay ƒë·ªïi."
    ],
    fear: [
        "Can ƒë·∫£m ƒë·ªëi di·ªán v√† v∆∞·ª£t qua n·ªói s·ª£.",
        "N·ªói s·ª£ l√† t√≠n hi·ªáu‚Äîchuy·ªÉn h√≥a n√≥ th√†nh s·ª± t·ª± tin.",
        "M·ªçi th·ª≠ th√°ch ƒë·ªÅu ·∫©n c∆° h·ªôi."
    ],
    unknown: [
        "M√¨nh kh√¥ng ch·∫Øc l·∫Øm, th·ª≠ ch·ª•p l·∫°i nh√©!",
        "Kh√¥ng ph√°t hi·ªán r√µ c·∫£m x√∫c. B·∫°n th·ª≠ l·∫ßn n·ªØa nh√©."
    ]
};

// ====== DOM ======
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const btnCapture = document.getElementById("btnCapture");

const popup = document.getElementById("popup");
const snapshot = document.getElementById("snapshot");
const emoIcon = document.getElementById("emoIcon");
const emoLabel = document.getElementById("emoLabel");
const titleAsk = document.getElementById("titleAsk");
const letter = document.getElementById("letter");
const msgBox = document.getElementById("msgBox");
const btnClose = document.getElementById("btnClose");

// ====== STATE ======
let modelsReady = false;
let detecting = false;
let popupShown = false;
let videoReady = false;
let ssdAvailable = false;
let tinyAvailable = false;

// ====== UTIL ======
const pick = (arr) => arr[Math.floor(Math.random() * arr.length)];
const hideEl = (el) => el.classList.add("hidden");
const showEl = (el) => el.classList.remove("hidden");

function resetPopupUI() {
    // gi·ªëng PyQt: khi m·ªõi m·ªü popup, hi·ªán title + th∆∞ + pointer; ·∫©n message
    emoIcon.src = "";
    emoLabel.textContent = "‚Ä¶";
    showEl(titleAsk);
    showEl(letter);
    hideEl(msgBox);
    // h·ªßy click c≈© n·∫øu c√≥ ƒë·ªÉ tr√°nh nh√¢n ƒë√¥i listener
    letter.onclick = null;
}

function showPopup() {
    popup.setAttribute("aria-hidden", "false");
    popup.style.display = "flex";
    popupShown = true;
}

function hidePopup() {
    popup.setAttribute("aria-hidden", "true");
    popup.style.display = "none";
    popupShown = false;
    resetPopupUI(); // chu·∫©n b·ªã cho l·∫ßn sau
}

// ====== INIT (KH√îNG m·ªü popup ·ªü ƒë√¢y) ======
async function init() {
    // ƒë·∫£m b·∫£o modal ·∫©n khi kh·ªüi ƒë·ªông
    hideEl(popup);

    // camera
    try {
        // Prefer a built-in / computer webcam when multiple devices are present.
        async function getPreferredCameraStream() {
            // enumerate devices
            let devices = await navigator.mediaDevices.enumerateDevices();
            // if labels are empty (no permission yet), request a temporary stream to prompt user and then re-enumerate
            const labelsEmpty = devices.every(d => !d.label);
            if (labelsEmpty) {
                console.log('[camera] labels empty, requesting temporary permission to enumerate devices');
                let tmpStream = null;
                try {
                    tmpStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                    // stop tracks immediately after permission granted
                    tmpStream.getTracks().forEach(t => t.stop());
                } catch (e) {
                    console.warn('[camera] temporary permission denied or failed', e);
                }
                devices = await navigator.mediaDevices.enumerateDevices();
            }
            const videoDevices = devices.filter(d => d.kind === 'videoinput');
            console.log('[camera] available devices:', videoDevices.map(d => ({ id: d.deviceId, label: d.label })));

            if (videoDevices.length === 0) {
                // no device found
                return navigator.mediaDevices.getUserMedia({ video: true, audio: false });
            }

            // heuristics to prefer built-in/computer webcams
            const positive = ['integrated', 'internal', 'built-in', 'built in', 'webcam', 'face time', 'facetime', 'logitech', 'hd'];
            const negative = ['iphone', 'android', 'phone', 'pixel', 'galaxy'];

            // try to find device whose label matches positive and not negative
            let chosen = videoDevices.find(d => {
                const lbl = (d.label || '').toLowerCase();
                return positive.some(p => lbl.includes(p)) && !negative.some(n => lbl.includes(n));
            });

            if (!chosen) {
                // try a device that does not look like a phone
                chosen = videoDevices.find(d => {
                    const lbl = (d.label || '').toLowerCase();
                    return !negative.some(n => lbl.includes(n));
                });
            }

            if (chosen && chosen.deviceId) {
                console.log('[camera] chosen device:', chosen.label || chosen.deviceId);
                try {
                    return await navigator.mediaDevices.getUserMedia({ video: { deviceId: { exact: chosen.deviceId } }, audio: false });
                } catch (e) {
                    console.warn('[camera] failed to open chosen device, falling back', e);
                }
            }

            // fallback to facingMode user
            try {
                return await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
            } catch (e) {
                // last resort
                return await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
            }
        }

        const stream = await getPreferredCameraStream();
        video.srcObject = stream;
        // listen for playing to mark video ready
        video.addEventListener('playing', () => {
            console.log('[camera] video playing -> ready');
            videoReady = true;
            // enable capture only when models are ready too
            btnCapture.disabled = !(modelsReady && videoReady);
        }, { once: true });
    } catch (e) {
        alert("Kh√¥ng m·ªü ƒë∆∞·ª£c camera. H√£y ki·ªÉm tra quy·ªÅn truy c·∫≠p.");
        console.error(e);
    }

    // models - check manifests first to avoid 404 for missing model builds
    try {
        async function manifestExists(name) {
            try {
                const url = `${MODEL_URL}/${name}_model-weights_manifest.json`;
                const r = await fetch(url, { method: 'GET' });
                return r.ok;
            } catch (e) {
                return false;
            }
        }

        const needFaceExpr = await manifestExists('face_expression');
        const hasTiny = await manifestExists('tiny_face_detector');
        const hasSsd = await manifestExists('ssd_mobilenetv1');

        if (!needFaceExpr) {
            throw new Error('Required model face_expression not found in ' + MODEL_URL);
        }

        // load face expression for sure
        await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);

        // load detectors that exist and set flags
        if (hasSsd) {
            await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
            ssdAvailable = true;
            console.log('[models] ssdMobilenetv1 loaded');
        }
        if (hasTiny) {
            await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
            tinyAvailable = true;
            console.log('[models] tinyFaceDetector loaded');
        }

        if (!ssdAvailable && !tinyAvailable) {
            throw new Error('No face detector model found (ssd_mobilenetv1 or tiny_face_detector) in ' + MODEL_URL);
        }

        modelsReady = true;
        console.log('[models] models loaded, ssd=', ssdAvailable, 'tiny=', tinyAvailable);
        btnCapture.disabled = !(modelsReady && videoReady);
    } catch (e) {
        console.error('Load models l·ªói:', e);
        btnCapture.disabled = true;
    }
}

// ====== EMOTION HELPERS ======
function mapTopEmotion(expressions) {
    const mapped = {
        happy: expressions.happy ?? 0,
        sad: expressions.sad ?? 0,
        angry: expressions.angry ?? 0,
        fear: expressions.fearful ?? (expressions.fear ?? 0)
    };
    let key = "unknown", score = 0;
    Object.entries(mapped).forEach(([k, v]) => { if (v > score) { score = v; key = k; } });
    return key;
}

// ====== CAPTURE FLOW (ch·ªâ g·ªçi khi ng∆∞·ªùi d√πng b·∫•m n√∫t / Space) ======
async function captureAndAnalyze() {
    if (!modelsReady || detecting) return;
    detecting = true;
    btnCapture.disabled = true;

    try {
        const w = video.videoWidth, h = video.videoHeight;
        if (!w || !h) throw new Error("Video ch∆∞a s·∫µn s√†ng");

        // crop vu√¥ng nh∆∞ b·∫£n Python
        const minEdge = Math.min(w, h);
        const sx = (w - minEdge) / 2, sy = (h - minEdge) / 2;
        canvas.width = minEdge; canvas.height = minEdge;
        const ctx = canvas.getContext("2d");
        ctx.drawImage(video, sx, sy, minEdge, minEdge, 0, 0, minEdge, minEdge);
        const dataUrl = canvas.toDataURL("image/jpeg", 0.9);
        // Show the original captured square image in the popup.
        // Keep this as the snapshot displayed to the user.
        snapshot.src = dataUrl;

        // detect
        // use the canvas element directly as input for face-api (avoid bufferToImage Blob error)
        const input = canvas; // canvas already contains the cropped image
        console.log('[detect] running detection, ssdAvailable=', ssdAvailable, 'tinyAvailable=', tinyAvailable);
        // Robust detection routine: try SSD (if available), then multiple Tiny configs
        async function attemptDetect(img) {
            // try SSD first
            if (ssdAvailable) {
                console.log('[detect] trying SSD minConfidence=0.3');
                const d = await faceapi.detectAllFaces(img, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.3 })).withFaceExpressions();
                if (d && d.length) return { detections: d, method: 'ssd' };
            }

            if (tinyAvailable) {
                const tinyConfigs = [
                    { inputSize: 512, scoreThreshold: 0.25 },
                    { inputSize: 416, scoreThreshold: 0.2 },
                    { inputSize: 320, scoreThreshold: 0.15 },
                    { inputSize: 256, scoreThreshold: 0.12 }
                ];
                for (const cfg of tinyConfigs) {
                    try {
                        console.log('[detect] trying tiny', cfg);
                        const d = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions(cfg)).withFaceExpressions();
                        if (d && d.length) return { detections: d, method: `tiny-${cfg.inputSize}-${cfg.scoreThreshold}` };
                    } catch (e) {
                        console.warn('[detect] tiny attempt failed', cfg, e);
                    }
                }
                // last resort: detect single face with very low threshold
                try {
                    console.log('[detect] trying detectSingleFace tiny fallback');
                    const single = await faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions({ inputSize: 512, scoreThreshold: 0.08 })).withFaceExpressions();
                    if (single) return { detections: [single], method: 'tiny-single-fallback' };
                } catch (e) {
                    console.warn('[detect] single fallback failed', e);
                }
            }

            return { detections: [], method: 'none' };
        }

        const detectResult = await attemptDetect(input);
        const detections = detectResult.detections || [];
        console.log('[detect] method used:', detectResult.method);

        resetPopupUI(); // tr·∫°ng th√°i m·ªü ƒë·∫ßu c·ªßa popup

        console.log('[detect] detections length=', detections.length, detections);
        if (!detections.length) {
            // Kh√¥ng th·∫•y m·∫∑t ‚Üí unknown nh∆∞ Python
            emoIcon.src = EMO_ICON.unknown;
            emoLabel.textContent = EMO_LABEL.unknown;
            // phong b√¨ m·ªü ‚Üí hi·ªán th√¥ng ƒëi·ªáp unknown khi click
            letter.onclick = () => {
                hideEl(titleAsk);
                hideEl(letter);
                msgBox.textContent = pick(EMO_MSG.unknown);
                showEl(msgBox);
            };
            showPopup();
            return;
        }

        // Ch·ªçn m·∫∑t l·ªõn nh·∫•t
        const biggest = detections.reduce((max, cur) =>
            cur.detection.box.area > max.detection.box.area ? cur : max
        );

        const key = mapTopEmotion(biggest.expressions);
        emoIcon.src = EMO_ICON[key] || "";
        emoLabel.textContent = EMO_LABEL[key] || EMO_LABEL.unknown;

        // Crop the face ROI from canvas for internal use (e.g., if you want to
        // save/send the face crop). Important: do NOT overwrite the visible
        // `snapshot.src` ‚Äî keep showing the original captured image to the user.
        let faceCropDataUrl = null;
        try {
            const box = biggest.detection.box;
            const faceCanvas = document.createElement('canvas');
            faceCanvas.width = box.width; faceCanvas.height = box.height;
            const fctx = faceCanvas.getContext('2d');
            // source coordinates were drawn centered into canvas earlier using sx,sy
            // our canvas is the cropped square, so box.x and box.y are relative to canvas
            fctx.drawImage(canvas, box.x, box.y, box.width, box.height, 0, 0, box.width, box.height);
            faceCropDataUrl = faceCanvas.toDataURL('image/jpeg', 0.9);
            // If you later want to display the crop instead, set snapshot.src = faceCropDataUrl;
        } catch (e) {
            // fallback: keep original captured image visible; store the full canvas data if needed
            faceCropDataUrl = canvas.toDataURL('image/jpeg', 0.9);
        }

        // click phong b√¨ ƒë·ªÉ l·ªô th√¥ng ƒëi·ªáp t∆∞∆°ng ·ª©ng
        letter.onclick = () => {
            hideEl(titleAsk);
            hideEl(letter);
            msgBox.textContent = pick(EMO_MSG[key] || EMO_MSG.unknown);
            showEl(msgBox);
        };

        showPopup();

    } catch (e) {
        console.error(e);
        // trong tr∆∞·ªùng h·ª£p l·ªói khi ng∆∞·ªùi d√πng ƒë√£ b·∫•m, ta v·∫´n m·ªü popup b√°o th·ª≠ l·∫°i
        resetPopupUI();
        emoIcon.src = "";
        emoLabel.textContent = "Th·ª≠ l·∫°i üòï";
        letter.onclick = () => {
            hideEl(titleAsk);
            hideEl(letter);
            msgBox.textContent = pick(EMO_MSG.unknown);
            showEl(msgBox);
        };
        showPopup();
    } finally {
        detecting = false;
        btnCapture.disabled = !modelsReady;
    }
}

// ====== EVENTS ======
// Soft restart helper: when user wants to 'restart' the app without reloading the page
async function restartApp() {
    try {
        // If a popup is visible, hide it (acts like pressing the close button)
        if (popupShown) {
            hidePopup();
            return;
        }

        // stop existing camera tracks if any
        if (video && video.srcObject) {
            try {
                const tracks = video.srcObject.getTracks();
                tracks.forEach(t => t.stop());
            } catch (e) {
                console.warn('[restart] stop tracks failed', e);
            }
            video.srcObject = null;
        }

        // reset some internal flags and UI
        detecting = false;
        videoReady = false;
        popupShown = false;
        resetPopupUI();
        btnCapture.disabled = true;

        // re-run initialization (re-acquire camera and re-check models)
        await init();
    } catch (e) {
        console.error('[restart] failed', e);
    }
}

// 'r' key: act like close popup or restart app (but not a full page reload)
window.addEventListener('keydown', (ev) => {
    // ignore when user is typing into an input or textarea or contenteditable
    const active = document.activeElement;
    const tag = active && active.tagName ? active.tagName.toLowerCase() : '';
    const isTyping = active && (active.isContentEditable || tag === 'input' || tag === 'textarea');
    if (isTyping) return;

    if (ev.key === 'r' || ev.key === 'R') {
        ev.preventDefault();
        // call restartApp (it may be async, don't block)
        restartApp();
    }
});



btnCapture.addEventListener("click", captureAndAnalyze);

// Space: gi·ªëng Python ‚Äî ƒëang m·ªü popup th√¨ ƒë√≥ng, ng∆∞·ª£c l·∫°i th√¨ ch·ª•p
window.addEventListener("keydown", (ev) => {
    if (ev.code === "Space") {
        ev.preventDefault();
        if (popupShown) hidePopup();
        else captureAndAnalyze();
    }
});

btnClose.addEventListener("click", hidePopup);
window.addEventListener("load", init);
